{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faststylometry import Corpus\n",
    "\n",
    "from faststylometry import load_corpus_from_folder\n",
    "from faststylometry import tokenise_remove_pronouns_en\n",
    "from faststylometry import calculate_burrows_delta\n",
    "from faststylometry import predict_proba, calibrate, get_calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = load_corpus_from_folder(\"faststylometry/data/train\")\n",
    "\n",
    "train_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sense and Sensibility, written by Jane Austen (marked as \"janedoe\")\n",
    "# and Villette, written by Charlotte Bronte (marked as \"currerbell\", Bronte's real pseudonym)\n",
    "\n",
    "test_corpus = load_corpus_from_folder(\"faststylometry/data/test\", pattern=None)\n",
    "# You can set pattern to a string value to just load a subset of the corpus.\n",
    "\n",
    "test_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Uni 2022\\ISE\\Project\\github similabs\\SimiLabs_2022\\FastStylometry\\JypiterNotebook\\Burrows_Delta.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Uni%202022/ISE/Project/github%20similabs/SimiLabs_2022/FastStylometry/JypiterNotebook/Burrows_Delta.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m calculate_burrows_delta(train_corpus, test_corpus, vocab_size \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\shene\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\faststylometry\\burrows_delta.py:139\u001b[0m, in \u001b[0;36mcalculate_burrows_delta\u001b[1;34m(train_corpus, test_corpus, vocab_size)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_burrows_delta\u001b[39m(train_corpus: Corpus, test_corpus: Corpus, vocab_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m    132\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    Calculate the Burrows' Delta statistic for the test corpus vs every author's subcorpus in the training corpus.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    :param train_corpus: A corpus of known authors, which we will use as a benchmark to compare to the test corpus by an unknown author.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39m    :return: A DataFrame of Burrows' Delta values for each author in the training corpus.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     get_top_tokens(train_corpus, vocab_size)\n\u001b[0;32m    140\u001b[0m     get_token_counts(train_corpus)\n\u001b[0;32m    141\u001b[0m     get_token_counts_by_author(train_corpus)\n",
      "File \u001b[1;32mc:\\Users\\shene\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\faststylometry\\burrows_delta.py:19\u001b[0m, in \u001b[0;36mget_top_tokens\u001b[1;34m(corpus, vocab_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_top_tokens\u001b[39m(corpus: Corpus, vocab_size: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m    Identify the n highest ranking tokens in the corpus.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m    :return: A list of the n most common tokens in the corpus.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     \u001b[39massert\u001b[39;00m (\u001b[39mlen\u001b[39m(corpus\u001b[39m.\u001b[39mtokens) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)  \u001b[39m# you should have tokenised the corpus.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     token_freqs \u001b[39m=\u001b[39m Counter()\n\u001b[0;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m token_seq \u001b[39min\u001b[39;00m corpus\u001b[39m.\u001b[39mtokens:\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "calculate_burrows_delta(train_corpus, test_corpus, vocab_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(train_corpus, test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_values =  np.arange(0, 3, 0.1)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_values, train_corpus.probability_model.predict_proba(np.reshape(x_values, (-1, 1)))[:,1])\n",
    "plt.xlabel(\"Burrows delta\")\n",
    "plt.ylabel(\"Probability of same author\")\n",
    "plt.title(\"Calibration curve of the Burrows Delta probability model\\nUsing Logistic Regression with correction for class imbalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths, deltas = get_calibration_curve(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = train_corpus.probability_model.predict_proba(np.reshape(deltas, (-1, 1)))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(ground_truths, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=1, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating curve of the Burrows\\' Delta classifier\\noperating on entire books')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the training corpus as the \"test corpus\", re-tokenise it, and segment it this time\n",
    "test_corpus = load_corpus_from_folder(\"faststylometry/data/train\")\n",
    "test_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_corpus = test_corpus.split(80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = calculate_burrows_delta(train_corpus, split_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z_scores = split_test_corpus.df_author_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_matrix = pca_model.fit_transform(df_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df_z_scores.index.map(lambda x : re.sub(\" - .+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_by_author = pd.DataFrame(pca_matrix)\n",
    "df_pca_by_author[\"author\"] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15)) \n",
    "\n",
    "for author, pca_coordinates in df_pca_by_author.groupby(\"author\"):\n",
    "    plt.scatter(*zip(*pca_coordinates.drop(\"author\", axis=1).to_numpy()), label=author)\n",
    "for i in range(len(pca_matrix)):\n",
    "    plt.text(pca_matrix[i][0], pca_matrix[i][1],\"  \" + df_z_scores.index[i], alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Representation using PCA of works in training corpus\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f918ce47fab067f73100f39a186d0777f1424220c0cd1db69dcac667ab6d835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
